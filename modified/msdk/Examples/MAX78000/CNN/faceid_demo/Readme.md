# MAX78000 FaceID Demo

## Overview
The FaceID Demo software demonstrates identification of a number of persons from their facial images using MAX78000 EVKit.

For this purpose, the CNN model generates a 512-length embedding for a given image, whose distance to whole embeddings stored for each subject is calculated. The image is identified as either one of these subjects or “Unknown”, depending on the embedding distances.

The CNN model is trained with the VGGFace-2 dataset using MTCNN and FaceNet models for embedding generation.

The code is auto-generated by the `ai8x-synthesis` tool and runs a known-answer test with a pre-defined input sample.

## Software

### Project Usage

Universal instructions on building, flashing, and debugging this project can be found in the **[MSDK User Guide](https://analog-devices-msdk.github.io/msdk/USERGUIDE/)**.

### Project-Specific Build Notes

* This project comes pre-configured for the MAX78000EVKIT.  See [Board Support Packages](https://analog-devices-msdk.github.io/msdk/USERGUIDE/#board-support-packages) in the UG for instructions on changing the target board.

### Host Application

#### Prerequisites
- Python 3.6.9 or higher (tested for 3.6.9, 3.7.7 and 3.8.1)
- NumPy (>1.18)
- Scipy (1.4)
- PyQt5 (5.9.2)
- OpenCv (>3.4)
- PySerial (>3.4)
- MatplotLib (>3.2)
- PyTorch (>1.3.1)
- TorchVision (>0.5.0)

If an `ai8x-synthesis` virtual environment does not already exist, follow the instructions in the main repository before continuing.

Add the additional packages using:

```shell
(ai8x-synthesis) $ pip3 install -r requirements-faceid.txt
```

#### Running the Host Application

Navigate to directory `demo` and run the `run_demo.py` script:

```bash
$ cd Examples/MAX78000/CNN/faceid_demo/demo
$ python run_demo.py -c <COM_PORT>
```

`<COM_PORT>` is the Windows serial port identifier (e.g., `COM1`) or a Linux or macOS device (e.g., `/dev/tty.usbserial-D308XSRX`)

When the demo window is open, it is possible to load images from disk or capture images from the PC web cam. Currently, the app database includes images for five female and five male celebrities.

## CNN Model Design
### Problem Definition
* Identify people from three-channel (RGB) frontal facial images, i.e., portraits.
* A small amount of rotation should be acceptable for robustness.

### Approach
The main approach in the literature is composed of three steps:

- Face Extraction: Detection of the faces in the image and extract a rectangular sub-image that contains only a face.
- Face Alignment: The rotation angles (in 3D) of the face in the image is found to compensate its effect by affine transformation.
- Face Identification: The extracted sub-image is used to identify the person.

In this project, the aim is to run all those steps in a single MAX78000 device, so the approach is to identify individual faces from uncropped portraits, each image containing a single face only.

Then, the embeddings (Face ID) are created by a FaceNet [2] model as seen below, and these embeddings as the target. There is no need to deal with center loss, triplet loss etc, since those are assumed to be covered by the FaceNet model. The loss used in the model development will be Mean Square Error (MSE) between the target and predicted embeddings.

### CNN Model
The CNN model synthesized for MAX78000 is a 9-layer sequential model as shown below. It takes a 160×120 RGB image from the input and returns an embedding of length 512 corresponding to the image.

```python
class AI85FaceIDNet(nn.Module):
    """
    Simple FaceNet Model
    """
    def __init__(
            self,
            num_classes=None, 
            num_channels=3,
            dimensions=(160, 120),
            bias=True,
    ):
        super(AI85FaceIDNet, self).__init__()

        self.conv1 = ai8x.FusedConv2dReLU(num_channels, 16, 3, padding=1,
                                          bias=False)
        self.conv2 = ai8x.FusedMaxPoolConv2dReLU(16, 32, 3, pool_size=2, pool_stride=2,
                                                 padding=1, bias=False)
        self.conv3 = ai8x.FusedMaxPoolConv2dReLU(32, 32, 3, pool_size=2, pool_stride=2,
                                                 padding=1, bias=bias)
        self.conv4 = ai8x.FusedMaxPoolConv2dReLU(32, 64, 3, pool_size=2, pool_stride=2,
                                                 padding=1, bias=bias)
        self.conv5 = ai8x.FusedMaxPoolConv2dReLU(64, 64, 3, pool_size=2, pool_stride=2,
                                                 padding=1, bias=bias)
        self.conv6 = ai8x.FusedConv2dReLU(64, 64, 3, padding=1, bias=bias)
        self.conv7 = ai8x.FusedConv2dReLU(64, 64, 3, padding=1, bias=bias)
        self.conv8 = ai8x.FusedMaxPoolConv2d(64, 512, 1, pool_size=2, pool_stride=2,
                                             padding=0, bias=False)
        self.avgpool = ai8x.AvgPool2d((5, 3))

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = self.conv4(x)
        x = self.conv5(x)
        x = self.conv6(x)
        x = self.conv7(x)
        x = self.conv8(x)
        x = self.avgpool(x)
        return x
```


## References
[1] MTCNN: https://arxiv.org/ftp/arxiv/papers/1604/1604.02878.pdf

[2] FaceNet: https://arxiv.org/pdf/1503.03832.pdf
